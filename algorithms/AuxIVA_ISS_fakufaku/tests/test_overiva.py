import numpy as np
import pyroomacoustics as pra
from scipy.io import wavfile
import piva

# We use several sound samples for each source to have a long enough length
wav_files = [
    [
        "examples/input_samples/cmu_arctic_us_axb_a0004.wav",
        "examples/input_samples/cmu_arctic_us_axb_a0005.wav",
        "examples/input_samples/cmu_arctic_us_axb_a0006.wav",
    ],
    [
        "examples/input_samples/cmu_arctic_us_aew_a0001.wav",
        "examples/input_samples/cmu_arctic_us_aew_a0002.wav",
        "examples/input_samples/cmu_arctic_us_aew_a0003.wav",
    ],
]


def test_auxiva():

    # STFT frame length
    L = 256

    # Room 4m by 6m
    room_dim = [8, 9]

    # source location
    source = np.array([1, 4.5])

    # create an anechoic room with sources and mics
    room = pra.ShoeBox(room_dim, fs=16000, max_order=0)

    # get signals
    signals = [
        np.concatenate([wavfile.read(f)[1].astype(np.float32) for f in source_files])
        for source_files in wav_files
    ]
    delays = [1.0, 0.0]
    locations = [[2.5, 3], [2.5, 6]]

    # add mic and good source to room
    # Add silent signals to all sources
    for sig, d, loc in zip(signals, delays, locations):
        room.add_source(loc, signal=np.zeros_like(sig), delay=d)

    # add microphone array
    room.add_microphone_array(
        pra.MicrophoneArray(
            np.c_[
                [6.5, 4.49],
                [6.5, 4.51],
                [6.5, 4.53],
                [6.5, 4.55],
                [6.5, 4.57],
                [6.5, 4.59],
            ],
            fs=room.fs,
        )
    )

    # compute RIRs
    room.compute_rir()

    # Record each source separately
    separate_recordings = []
    for source, signal in zip(room.sources, signals):

        source.signal[:] = signal

        room.simulate()
        separate_recordings.append(room.mic_array.signals)

        source.signal[:] = 0.0
    separate_recordings = np.array(separate_recordings)

    # Mix down the recorded signals
    mics_signals = np.sum(separate_recordings, axis=0)

    # START BSS
    ###########

    # shape == (n_chan, n_frames, n_freq)
    X = pra.transform.analysis(mics_signals.T, L, L, zp_front=L // 2, zp_back=L // 2)

    # Run AuxIVA
    Y = piva.auxiva_cpp(X, n_src=2, n_iter=20, proj_back=True)
    # Y = piva.overiva(X, n_src=2, n_iter=20, proj_back=True)
    # Y = pra.bss.auxiva(X, n_iter=20, proj_back=True)

    # run iSTFT
    y = pra.transform.synthesis(Y, L, L, zp_back=L // 2, zp_front=L // 2).T

    # Compare SIR
    #############
    ref = np.moveaxis(separate_recordings, 1, 2)
    y_aligned = y[:, L // 2 : ref.shape[1] + L // 2]

    mse = np.minimum(
        np.mean((ref[:, :, 0] - y_aligned) ** 2),
        np.mean((ref[::-1, :, 0] - y_aligned) ** 2),
    )
    input_variance = np.var(mics_signals[:, :])

    print("Relative MSE (expect less than 1e-2):", mse / input_variance)

    assert (mse / input_variance) < 1e-2


if __name__ == "__main__":
    test_auxiva()
